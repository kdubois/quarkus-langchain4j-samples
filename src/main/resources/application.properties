quarkus.langchain4j.openai.api-key=demo

%dev.quarkus.mailer.mock=false

quarkus.langchain4j.easy-rag.path=src/main/resources/catalog

booking.daystostart=14
booking.daystoend=50

# With Podman Desktop
#quarkus.langchain4j.openai.base-url=http://localhost:41139/v1

# With Ollama
quarkus.langchain4j.openai.base-url=http://localhost:11434/v1
# Configure server to use a specific model
quarkus.langchain4j.openai.chat-model.model-name=granite-3.1-8b-instruct-GGUF
quarkus.langchain4j.openai.embedding-model.model-name=granite-3.1-8b-instruct-GGUF

# With ChatGPT
# Configure openai server to use a specific model
#quarkus.langchain4j.openai.chat-model.model-name=gpt-4o

# Choose a low temperature to minimize hallucination
quarkus.langchain4j.openai.chat-model.temperature=0
# Set timeout to 3 minutes (local LLM can be quite slow)
quarkus.langchain4j.openai.timeout=180s
# Enable logging of both requests and responses
 quarkus.langchain4j.openai.log-requests=true
 quarkus.langchain4j.openai.log-responses=true

quarkus.langchain4j.openai.image-generation.chat-model.model-name=dall-e-3

# You can download the gorilla model from https://huggingface.co/TheBloke/gorilla-7B-GGUF/blob/main/Gorilla-7B.Q4_K_M.gguf and run it with eg. Podman AI Lab:
quarkus.langchain4j.openai.image-model.base-url=https://api.openai.com/v1/
quarkus.langchain4j.openai.image-model.persist=true
quarkus.langchain4j.openai.image-model.size=1792x1024